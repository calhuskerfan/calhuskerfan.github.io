---
layout: post
title: SR Queue Consumer
description: SR Queue Consumer
tags:
- dotnet
- GitHub Pages
- csharp
---

> FIFO and a Galaxy Far Far Away

The SR Queue Consumer project explores a message queue consumer designed to  increase throughput of message transformations in a First In First Out (FIFO) manner. Its primary benefit is low overhead to maintain message order during the processing cycle. It is particulary efficient when the message transformation time is a significant piece of the overall handling time. It was inspired by the intersection of a problem I was working on and a patent for Disney’s Millennium Falcon: Smugglers Run attraction.

This document assumes some level of familiarity with [message orientated middleware](https://en.wikipedia.org/wiki/Message-oriented_middleware) concepts.

## Background

Millennium Falcon: Smugglers Run is an interactive motion simulator ride that puts a crew of 6 riders into the cockpit of the Millennium Falcon. An imaginative component of the ride is its loading and segmentation which allow for high throughput of riders (lower wait times) with an immersive loading experience. Each crew waits their turn in the chess room of the Millennium Falcon before being loaded into their individual 'cockpit' for the ride. To create the experience and the short(er) wait times there are 4 ride turntables each with 7 pods, where each pod encapsulates the ride experience for a crew. The turntable rotates the pods to the riders to maintain the sense that you are walking from the chess room into the cockpit.

This [article](https://www.bizjournals.com/orlando/news/2019/10/04/how-it-works-patent-behind-disneys-millennium.html) has a detailed description (apologies if you hit a paywall). There is another, [shorter description](https://disneydiary.com/2019/10/new-disney-patent-shows-how-the-millennium-falcon-ride-works/) available. Finally, the [patent](https://patents.google.com/patent/EP3628383A1/en) is also available.

## Introduction

As happenstance would have it, that patent was somewhere in my mind while I was working on some throughput issues for a FIFO queue. In my case the per message transformation time was a significant bottleneck in the system. 

There are a few [general patterns for this](https://en.wikipedia.org/wiki/Message_queue), two of the most popular being:

- Process messages using competing consumer pattern with a SequenceId that re-assembles the order in a post processing step.
- Partitioning messages within a queue(s) to support parallel processing of each. Assuming partitioning is feasible for a use case, the speed for the entire population of messages increases, however messages in a partition are still handled serially.

I did not want to worry about the re-assembly and wanted faster 'per partition' processing.

Taking inspiration from the segmented turntable construct envisioned in Smugglers Run the system is able to increase throughput, maintain FIFO order, and eliminate any re-assembly when messages are complete.  The analogy being wait times for the inbound queue are reduced by having multiple messages transformed at a time as they 'rotate' from entry to exit. They exit in the same order they arrived, but experienced the ride (transformation) separately.

The results is that we do not need to monitor the processing of each message relative to its neighbors, we are only concerned with a message once it has arrived at the exit.

TL;DR. I just want to see [the code](https://github.com/calhuskerfan/srqc)


## System Overview

The system has the following major components

![image]({{ site.baseurl }}/assets/images/srloader.drawio.svg)

The system contains a virtual carousel with a configurable number of pods. Pods operate on a message via a thread assigned to the pod. The system loads and unloads the pods in order. As pods are loaded and unloaded they are 'rotated' to allow the next message to start processing. The system does not have to concern itself when any of the messages on the carousel finish relative to each other. If a message finishes processing before it reaches the exit it simply waits. If a message is rotated to the exit while it is still running the carousel waits until it is completed, unloads it, and continues operation.

So hypothetically if a message takes 250 msec to process then our maximum message rate is 4 messages / sec if processed in a serial manner, however if we can process 3 'pods' at a time we increase our rate to 12 messages / sec. While we will not see the theoretical throughput due to sequencing overhead and message timing variation we will see a significant improvement compared to serial processing.

| Component | Description |
|-----------|-------------|
| Inbound Queue | A typical inbound queue in a Message Orientated Middleware (MOM) style application. |
| Staging Area | A small internal queue that helps to optimize the loading and unloading operations. |
| Message Loading | Monitors the staging area and the carousel state to place waiting messages from the staging area into a pod for processing. |
| Pod | Container that processes the message from inbound to outbound format on a thread. |
| Carousel | An organizational construct to maintain messages in their received order while they are processing. |
| Message Unloading | Monitors pods 'rotated' to the exit. If the message transformation is completed the message is unloaded. If it is still processing it will wait for completion before advancing. |
| Outbound Queue | Messages that have completed processing are placed in the outbound queue.

## Operation 

The following is a detailed description of the steps described above.

- Messages are added to the inbound queue by a message producer. This happens asynchronously to any loading, carousel, or unloading operations.
- Messages are admitted into the staging queue and it is monitored for capacity.
- Messages are loaded into a pod at the entry station, message processing thread is started, and the carousel is rotated.
- This process continues until the message is rotated to the exit. Upon completion the message is unloaded and delivered to the exit queue.
- The carousel is rotated so that the now empty pod is moved to the entry to pick up another message.
- A new message is loaded, a spot is opened on the staging queue, and another message enters from the inbound queue.  The cycle continues.


## Benefits

Some benefits to this design include:

- Improved throughput when the message processing time is significant. Either through complex processing or waiting on I/O or services.
- The process is self contained.

## Limitations

A few notable limitations to the system.

- Diminishing returns as the message process time reduces. Eventually the overhead of thread synchronization hampers performance.
- Performance degradation by 'long pole' messages. Messages that take a significantly longer amount of time to process than their peers may drag down the throughput relative to a competing consumer pattern.
- More management of 'in process messages'. By allowing [number of pods] + [staging area size] messages into the system simultaneously we lose some of the message resilience the inbound queue provides.
- The transformation of the message must be self contained, I.e. the only target is the exit queue. If any portion of the processing has external side effects that include FIFO restrictions this pattern would not suffice since there is no synchronization of 'in flight' transformations.

## Running the Project

For the demonstration project the message transformation is simply a string update and a Thread.Sleep() to simulate processing time.

I used Windows 11, but any hardware running .[NET 9.0](https://dotnet.microsoft.com/en-us/download) should work without an issue.

Please refer to the project [Readme](https://github.com/calhuskerfan/srqc/blob/main/README.md) for details on running the project.

After logging information about the operations involved in processing, the output will resemble the following (timestamps and log level omitted):

```text
010350:001:0000165:Your new outbound message is: 350 brought to you from pod a0567460-0024-4fd0-b44b-9c6306a7a58a
total processing time: 9693.9849 msec.  Accumulated 'Serial' Time: 52509 msec.  Ratio: 5.416657911237308
```

where the first column is the message id, the second column is the pod that processed the message, the third is the configured delay (message processing simulation), and finally in the fourth column is the transformed message.

The summary line includes:

- Total processing time is the start to finish of the execution.
- Accumulated is the ideal time if all the messages were processed serially with no intra processing delays.- Ratio is the Accumulated / Total; the estimated througput improvement.

## Next Steps

The envisioned system did not make its way into a production product, so many things were left as “I
                will get to those”. A few include:

- Externalize the Types and logic for the pod and carousel. By templatizing the types for inbound and
                    outbound messages and externalizing the pod processing logic the system can be re-used.
- Tighten up the thread and event synchronization. There are some comments in the code.
 - Error Handling Patterns. What happens when a message fails, what should ripple upstream.
 - Run as an IHostedService.
 - Incorporate a common message queue, I.e. [rabbitmq](https://www.rabbitmq.com).

 ## Summary

In the end this project was primarily a thought exercise, however it was successful with the requirements that I had envisioned for it, namely:
            
- speeding up parallel processing of a FIFO queue where the bottleneck was the message processing itself.
- not adding any external complexities to maintain message order.
- minimizing 'at risk' messages

If nothing else it was an opportunity to look at a problem with a new lens and see what comes of it.

Your mileage may vary.